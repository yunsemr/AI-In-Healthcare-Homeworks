{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL-Faql-Cj7V"
      },
      "source": [
        "# Assignment 2\n",
        "\n",
        "In this assignment you will implement ResNet18.\n",
        "Read the comments carefully and insert your code where you see: <br><br><b>##### START OF YOUR CODE #####</b><br><br><b>##### END OF YOUR CODE #####</b><br><br>or for the inline codes you will see<br><br><b>##### INSERT YOUR CODE HERE #####</b>\n",
        "\n",
        "### The architecture of ResNet-18 is shown in the table.\n",
        "First, we will define a convolutional block with skip connection. Then, create the model using these blocks.<br><br>\n",
        "<img src=\"https://www.researchgate.net/profile/Paolo-Napoletano/publication/322476121/figure/tbl1/AS:668726449946625@1536448218498/ResNet-18-Architecture.png\" width=\"500\" alt=\"ResNet18 Architecture\">\n",
        "\n",
        "<br><sup>Image ref: Napoletano, Paolo, et al. ‘Anomaly Detection in Nanofibrous Materials by CNN-Based Self-Similarity’. Sensors (Basel, Switzerland), vol. 18, 01 2018, https://doi.org10.3390/s18010209.</sup>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X38vEzbBWFNt"
      },
      "source": [
        "#### I. ConvBlock\n",
        "<img src=\"https://www.researchgate.net/publication/334301817/figure/fig3/AS:778452965801986@1562609058538/Residual-block-of-ResNet18-with-a-1-1-convolutional-mapping-based-residual-unit-and.png\"><br>\n",
        "ResNet consists of convolutional (a) and identity (b) blocks. For ResNet-18 we will only use convolutional blocks. In this step you will write a class for convolutional block. The arguments will be:\n",
        "\n",
        "* ch_in: input channels\n",
        "* ch_out: output channels\n",
        "* s: strides\n",
        "* act: activation function\n",
        "\n",
        "The options for activation function are \"relu\", \"leaky_relu\" and \"gelu\".\n",
        "<br><br>\n",
        "<sup>Image ref: Owais, Muhammad, et al. ‘Artificial Intelligence-Based Classification of Multiple Gastrointestinal Diseases Using Endoscopy Videos for Clinical Diagnosis’. Journal of Clinical Medicine, vol. 8, 07 2019, p. 986, https://doi.org10.3390/jcm8070986.</sup>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "w4zlwn3H8ZUR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out, s, act):\n",
        "      super(ConvBlock,self).__init__()\n",
        "      # Initialize layers\n",
        "      ##### START OF YOUR CODE #####\n",
        "      self.ch_in = ch_in\n",
        "      self.ch_out =ch_out\n",
        "      self.s = s\n",
        "      self.bn = nn.BatchNorm2d(ch_out)\n",
        "      self.act = act\n",
        "\n",
        "      if self.act.lower() == \"relu\":\n",
        "        self.act = nn.ReLU()\n",
        "      elif act.lower() == \"leaky_relu\":\n",
        "        self.act = nn.Leaky_ReLU()\n",
        "      elif act.lower() == \"gelu\":\n",
        "        self.act = nn.GELU()\n",
        "\n",
        "      #convolutional layers of one block\n",
        "      if self.s == 1:\n",
        "        self.conv1 = nn.Conv2d(ch_in, ch_out, kernel_size = (1,1), stride = s, padding = 0)\n",
        "        self.conv2 = nn.Conv2d(ch_in, ch_out, kernel_size = (3,3), stride = s, padding = 1)\n",
        "        self.conv3 = nn.Conv2d(ch_out, ch_out, kernel_size = (3,3), stride = s, padding = 1)    \n",
        "      else:\n",
        "        self.conv1 = nn.Conv2d(ch_in, ch_out, kernel_size = (1,1), stride = s, padding = 0)\n",
        "        self.conv2 = nn.Conv2d(ch_in, ch_out, kernel_size = (3,3), stride = s, padding = 1)\n",
        "        self.conv3 = nn.Conv2d(ch_out, ch_out, kernel_size = (3,3), stride = s-1, padding = 1)\n",
        "      \n",
        "      ##### END OF YOUR CODE #####\n",
        "\n",
        "    def forward(self, X):\n",
        "      ##### START OF YOUR CODE #####      \n",
        "      x = self.conv1(X)\n",
        "      x = self.bn(x)\n",
        "      \n",
        "      y = self.conv2(X)\n",
        "      y = self.bn(y)\n",
        "      y = self.act(y)\n",
        "      y = self.conv3(y)\n",
        "      y = self.bn(y)\n",
        "\n",
        "      y += x # skip connection\n",
        "      X = self.act(y)\n",
        "      ##### END OF YOUR CODE #####\n",
        "      return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS8xDz-ncs1F"
      },
      "source": [
        "#### II. ResNet18 class\n",
        "Use the ConvBlock class to create ResNet18.\n",
        "* Add batch normalization and activation function after the first conv layer as well.\n",
        "* Examine the output sizes in the table above and use paddings and strides where needed.\n",
        "* Pytorch doesn't have a global average pooling layer. Instead you should reshape the image as (B, C, W*H) and calculate the mean of the last dimension without keeping the dims. It will result in a tensor of (B, C)\n",
        "* Add drop-out layer after average pooling.\n",
        "* Fully connected layer should be 512 x 1 as we have only 2 classes and we will use sigmoid function as the final activation layer.\n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Paolo-Napoletano/publication/322476121/figure/tbl1/AS:668726449946625@1536448218498/ResNet-18-Architecture.png\" width=\"500\" alt=\"ResNet18 Architecture\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Npd7BHRsdFqt"
      },
      "outputs": [],
      "source": [
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, act, drop_rate):\n",
        "      super(ResNet18, self).__init__()\n",
        "      # Initialize layers\n",
        "      ##### START OF YOUR CODE #####\n",
        "      self.drop_rate = drop_rate\n",
        "      self.drop_out = nn.Dropout2d(drop_rate)\n",
        "      self.max_pool = nn.MaxPool2d(kernel_size = (3,3), stride = (2,2), padding = (1,1))\n",
        "      self.avg_pool = nn.AvgPool2d(kernel_size = (7,7))\n",
        "      self.fully_connected = nn.Linear(512,1)\n",
        "      self.sigmoid = nn.Sigmoid()\n",
        "      self.bn = nn.BatchNorm2d(64)  \n",
        "      self.flatten = nn.Flatten()\n",
        "      self.act = act \n",
        "\n",
        "      if self.act.lower() == \"relu\":\n",
        "        self.act = nn.ReLU()\n",
        "      elif act.lower() == \"leaky_relu\":\n",
        "        self.act = nn.Leaky_ReLU()\n",
        "      elif act.lower() == \"gelu\":\n",
        "        self.act = nn.GELU()\n",
        "\n",
        "      #convolutional blocks\n",
        "      self.conv1 = nn.Conv2d(1, 64, kernel_size = (7,7), stride = (2,2), padding = (3,3))\n",
        "      \n",
        "      self.conv2_x = nn.Sequential(ConvBlock(64, 64, 1, act),\n",
        "                                   ConvBlock(64, 64, 1, act))\n",
        "      \n",
        "      self.conv3_x = nn.Sequential(ConvBlock(64, 128, 2, act),\n",
        "                                   ConvBlock(128, 128, 1, act))\n",
        "      \n",
        "      self.conv4_x = nn.Sequential(ConvBlock(128, 256, 2, act),\n",
        "                                   ConvBlock(256, 256, 1, act))\n",
        "      \n",
        "      self.conv5_x = nn.Sequential(ConvBlock(256, 512, 2, act),\n",
        "                                   ConvBlock(512, 512, 1, act))\n",
        "          \n",
        "      ##### END OF YOUR CODE #####\n",
        "\n",
        "    def forward(self, X):\n",
        "      ##### START OF YOUR CODE #####\n",
        "      X = self.conv1(X)\n",
        "      X = self.bn(X)\n",
        "      X = self.act(X)\n",
        "      X = self.max_pool(X)\n",
        "      X = self.conv2_x(X)\n",
        "      X = self.conv3_x(X)\n",
        "      X = self.conv4_x(X)\n",
        "      X = self.conv5_x(X)\n",
        "      X = self.avg_pool(X) \n",
        "      X = self.drop_out(X)\n",
        "      X = self.flatten(X)     \n",
        "      X = self.fully_connected(X)\n",
        "      X = self.sigmoid(X)\n",
        "      ##### END OF YOUR CODE #####\n",
        "      return X"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "# Print the summary of model\n",
        "#device = torch.device('cuda') --> For GPU\n",
        "model = ResNet18(\"relu\", .5) #.to(device) -->For GPU\n",
        "summary(model, (1, 256, 256))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03tV8XIz2Wpv",
        "outputId": "0f549865-9fbf-4c87-ace8-da60ac194f90"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           3,200\n",
            "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
            "              ReLU-3         [-1, 64, 128, 128]               0\n",
            "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
            "            Conv2d-5           [-1, 64, 64, 64]           4,160\n",
            "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
            "            Conv2d-7           [-1, 64, 64, 64]          36,928\n",
            "       BatchNorm2d-8           [-1, 64, 64, 64]             128\n",
            "              ReLU-9           [-1, 64, 64, 64]               0\n",
            "           Conv2d-10           [-1, 64, 64, 64]          36,928\n",
            "      BatchNorm2d-11           [-1, 64, 64, 64]             128\n",
            "             ReLU-12           [-1, 64, 64, 64]               0\n",
            "        ConvBlock-13           [-1, 64, 64, 64]               0\n",
            "           Conv2d-14           [-1, 64, 64, 64]           4,160\n",
            "      BatchNorm2d-15           [-1, 64, 64, 64]             128\n",
            "           Conv2d-16           [-1, 64, 64, 64]          36,928\n",
            "      BatchNorm2d-17           [-1, 64, 64, 64]             128\n",
            "             ReLU-18           [-1, 64, 64, 64]               0\n",
            "           Conv2d-19           [-1, 64, 64, 64]          36,928\n",
            "      BatchNorm2d-20           [-1, 64, 64, 64]             128\n",
            "             ReLU-21           [-1, 64, 64, 64]               0\n",
            "        ConvBlock-22           [-1, 64, 64, 64]               0\n",
            "           Conv2d-23          [-1, 128, 32, 32]           8,320\n",
            "      BatchNorm2d-24          [-1, 128, 32, 32]             256\n",
            "           Conv2d-25          [-1, 128, 32, 32]          73,856\n",
            "      BatchNorm2d-26          [-1, 128, 32, 32]             256\n",
            "             ReLU-27          [-1, 128, 32, 32]               0\n",
            "           Conv2d-28          [-1, 128, 32, 32]         147,584\n",
            "      BatchNorm2d-29          [-1, 128, 32, 32]             256\n",
            "             ReLU-30          [-1, 128, 32, 32]               0\n",
            "        ConvBlock-31          [-1, 128, 32, 32]               0\n",
            "           Conv2d-32          [-1, 128, 32, 32]          16,512\n",
            "      BatchNorm2d-33          [-1, 128, 32, 32]             256\n",
            "           Conv2d-34          [-1, 128, 32, 32]         147,584\n",
            "      BatchNorm2d-35          [-1, 128, 32, 32]             256\n",
            "             ReLU-36          [-1, 128, 32, 32]               0\n",
            "           Conv2d-37          [-1, 128, 32, 32]         147,584\n",
            "      BatchNorm2d-38          [-1, 128, 32, 32]             256\n",
            "             ReLU-39          [-1, 128, 32, 32]               0\n",
            "        ConvBlock-40          [-1, 128, 32, 32]               0\n",
            "           Conv2d-41          [-1, 256, 16, 16]          33,024\n",
            "      BatchNorm2d-42          [-1, 256, 16, 16]             512\n",
            "           Conv2d-43          [-1, 256, 16, 16]         295,168\n",
            "      BatchNorm2d-44          [-1, 256, 16, 16]             512\n",
            "             ReLU-45          [-1, 256, 16, 16]               0\n",
            "           Conv2d-46          [-1, 256, 16, 16]         590,080\n",
            "      BatchNorm2d-47          [-1, 256, 16, 16]             512\n",
            "             ReLU-48          [-1, 256, 16, 16]               0\n",
            "        ConvBlock-49          [-1, 256, 16, 16]               0\n",
            "           Conv2d-50          [-1, 256, 16, 16]          65,792\n",
            "      BatchNorm2d-51          [-1, 256, 16, 16]             512\n",
            "           Conv2d-52          [-1, 256, 16, 16]         590,080\n",
            "      BatchNorm2d-53          [-1, 256, 16, 16]             512\n",
            "             ReLU-54          [-1, 256, 16, 16]               0\n",
            "           Conv2d-55          [-1, 256, 16, 16]         590,080\n",
            "      BatchNorm2d-56          [-1, 256, 16, 16]             512\n",
            "             ReLU-57          [-1, 256, 16, 16]               0\n",
            "        ConvBlock-58          [-1, 256, 16, 16]               0\n",
            "           Conv2d-59            [-1, 512, 8, 8]         131,584\n",
            "      BatchNorm2d-60            [-1, 512, 8, 8]           1,024\n",
            "           Conv2d-61            [-1, 512, 8, 8]       1,180,160\n",
            "      BatchNorm2d-62            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-63            [-1, 512, 8, 8]               0\n",
            "           Conv2d-64            [-1, 512, 8, 8]       2,359,808\n",
            "      BatchNorm2d-65            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-66            [-1, 512, 8, 8]               0\n",
            "        ConvBlock-67            [-1, 512, 8, 8]               0\n",
            "           Conv2d-68            [-1, 512, 8, 8]         262,656\n",
            "      BatchNorm2d-69            [-1, 512, 8, 8]           1,024\n",
            "           Conv2d-70            [-1, 512, 8, 8]       2,359,808\n",
            "      BatchNorm2d-71            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-72            [-1, 512, 8, 8]               0\n",
            "           Conv2d-73            [-1, 512, 8, 8]       2,359,808\n",
            "      BatchNorm2d-74            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-75            [-1, 512, 8, 8]               0\n",
            "        ConvBlock-76            [-1, 512, 8, 8]               0\n",
            "        AvgPool2d-77            [-1, 512, 1, 1]               0\n",
            "        Dropout2d-78            [-1, 512, 1, 1]               0\n",
            "          Flatten-79                  [-1, 512]               0\n",
            "           Linear-80                    [-1, 1]             513\n",
            "          Sigmoid-81                    [-1, 1]               0\n",
            "================================================================\n",
            "Total params: 11,530,881\n",
            "Trainable params: 11,530,881\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.25\n",
            "Forward/backward pass size (MB): 93.51\n",
            "Params size (MB): 43.99\n",
            "Estimated Total Size (MB): 137.75\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}